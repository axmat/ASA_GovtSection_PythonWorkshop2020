{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example 2: Hospital Charges for Inpatients in the U.S.\n",
    "\n",
    "In this example we will be exploring a dataset provided by kaggle.com about hospital charges for inpatiens across a variety of providers in the U.S. The data and some accompanying information can be found on kaggle here:\n",
    "\n",
    "https://www.kaggle.com/speedoheck/inpatient-hospital-charges\n",
    "\n",
    "\n",
    "## Data Combining\n",
    "\n",
    "In Example 1 we saw an introduction to data science in Python, with a walkthrough using some of the most commonly applied functionality. As an avid user of R also, I included a porting the \"5 verbs of dplyr\" to Python in the pandas:\n",
    "\n",
    "* arrange: sort or order a data frame\n",
    "* select: subset your dataset down to particular columns/variables of interest\n",
    "* filter: subset your dataset down to particular rows/observations of interest\n",
    "* mutate: create and append new variables/columns to your dataset\n",
    "* summarize: compute aggregations, statistics, or other summaries of the data\n",
    "\n",
    "with the obligatory inclusion of being able to \"group by.\" Besides the parallel with dplyr functionality in R, these operations also constitute the core of most SQL queries. So, to say they are foundational is still probably an understatement!\n",
    "\n",
    "In this example we're going to combine the dataset from Example with the hospital charges dataset linked above. Then, we're going to look at some basic visualiations using the matplotlib library.\n",
    "\n",
    "### Reading the Data In"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "energy = pd.read_csv(\"Energy Census and Economic Data US 2010-2014.csv\")\n",
    "hospital = pd.read_csv(\"inpatientCharges.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "energy.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hospital.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Combining These Two Datasets\n",
    "\n",
    "Notice that these two datasets actually only have the state code in common, so we'll want to merge on that. The pandas library offers syntax and functionality very similar to SQL joins: left, right, inner, and outer. The entry point for all of these is with the merge() function, but there are more specific ways of performing joins if you take a deeper look at the pandas documentation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alldata = pd.merge(energy, hospital, left_on = \"StateCodes\", right_on = \"Provider State\", how = \"inner\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alldata.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cleaning the Hospital Charges\n",
    "\n",
    "Notice that the hospital charge variables are actually character as they include the dollar signs. Let's remove those and convert the variables to numeric for better use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# alldata[\"Average Covered Charges\"].head()\n",
    "alldata[\"Average Covered Charges\"] = pd.to_numeric(alldata[\"Average Covered Charges\"].str.replace(\"\\\\$|,\", \"\"))\n",
    "# alldata[\"Average Covered Charges\"].head()\n",
    "\n",
    "alldata[\"Average Total Payments\"] = pd.to_numeric(alldata[\"Average Total Payments\"].str.replace(\"\\\\$|,\", \"\"))\n",
    "alldata[\"Average Medicare Payments\"] = pd.to_numeric(alldata[\"Average Medicare Payments\"].str.replace(\"\\\\$|,\", \"\"))\n",
    "\n",
    "# alldata.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Some Basic Visualizations Using matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig1, ax1 = plt.subplots()\n",
    "\n",
    "ax1.hist(alldata[\"Average Total Payments\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig2, ax2 = plt.subplots()\n",
    "ax2.scatter(x = alldata[\"Average Medicare Payments\"], y = alldata[\"Average Total Payments\"], marker = 'o', c = alldata[\"Coast\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Some Basic Visualizations Using altair"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import altair as alt\n",
    "\n",
    "# Subset for plotting\n",
    "subdata = alldata[7000:10000].copy()\n",
    "\n",
    "alt.Chart(subdata).mark_point().encode(\n",
    "    x = \"Average Medicare Payments\",\n",
    "    y = \"Average Total Payments\",\n",
    "    color = \"Coast\")\n",
    "\n",
    "subdata[\"Coast_c\"] = subdata[\"Coast\"] == 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alt.Chart(subdata).mark_point().encode(\n",
    "    x = \"Average Medicare Payments\",\n",
    "    y = \"Average Total Payments\",\n",
    "    color = \"Coast_c\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alt.Chart(subdata).mark_bar().encode(\n",
    "    alt.X(\"Average Medicare Payments\", bin = True),\n",
    "    y = 'count()')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "We saw here how to perform simple, SQL-like merges/joins and the robustness of the pandas library to accomplish this as well.\n",
    "\n",
    "We also saw some basic visualizations using the matplotlib and altair libraries. \n",
    "\n",
    "This was all still just the tip of the iceberg!\n",
    "\n",
    "### Resources\n",
    "\n",
    "There are tons of galleries of examples online for visualizations using both of these libraries, but here are the home pages for them to start at:\n",
    "\n",
    "#### matplotlib\n",
    "\n",
    "https://matplotlib.org/2.0.2/index.html\n",
    "\n",
    "#### altair\n",
    "\n",
    "https://altair-viz.github.io/index.html\n",
    "\n",
    "### scikit-learn library for statistical analysis/modeling\n",
    "\n",
    "https://scikit-learn.org/stable/"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
